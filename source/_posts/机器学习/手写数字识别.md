---
title: 手写数字识别
date: 2020-02-20 13:43:51
categories: 机器学习
tags:
- 深度学习
- 手写数字识别
---
这个小项目的主要目的就是识别试卷上的**红色**手写成绩。下面分为几步对其进行介绍。
<!--more-->

一、图片数字提取
======
消除背景影响
------
由于我们所要提取的数字是红色的，所以我们要关注的只有红色像素点，其他的黑色或者白色像素点则不是我们要关注的。
出于这种考虑，我们可以将红色像素点三个通道的值均置为255，即将红色像素点置为白色。而将其他像素点三个通道的值均置为0，即将其他像素点置为黑色。
至于红色像素点的判断我比较简单粗暴，R通道的值大于200，并且B和G通道的值小于100。需要注意的一点是：opencv中图像采用的是**BGR**格式，而非RGB格式。
 然后再将其转化为灰度图并且二值化。

二值图像连通域标记
------
通过上面的操作，我们已经得到了上面只有数字的二值图像。接下来我们要采用连通域标记的方法将数字从图像中提取出来。
关于连通域标记算法，可以看看这篇博客：[https://www.cnblogs.com/ronny/p/img_aly_01.html](https://www.cnblogs.com/ronny/p/img_aly_01.html) 。
由于此次项目的重点并不是数字图像处理，所以我并没有自己实现该算法，而是调用的scikit-image库中的API。

调整图像
------
由于我们的神经网络是用mnist数据集训练的，而mnist数据集中的图像大小为28×28。所以我们要对提取出的图像进行一些调整。包括增加一些边框，以及调整为28×28的图像。

图片数字提取的代码放在了imgprocess.py模块中。
代码如下：
```py
import cv2
import numpy as np
from skimage.measure import label,regionprops

# 消除传入图片的噪音，并将其二值化，返回处理后的图片
def image_init(image_path):
    # 读入图片
    img = cv2.imread(image_path)
    # 彩色图像，shape为三维，第三维是3通道
    row_length,column_length,_ = img.shape

    # 所有非红色像素点置为黑色，红色像素点置为白色
    for row_index in range(row_length):
        for column_index in range(column_length):
            if (img[row_index,column_index,2] > 200)\
            and (img[row_index,column_index,0] < 100)\
            and (img[row_index,column_index,1] < 100):
                img[row_index,column_index] = 255
            else:
                img[row_index,column_index] = 0

    # 将彩图转化为灰度图
    # 需要注意的是，由于之前的处理，这里的灰度图相当于经过了二值化
    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    # 返回处理后的图片
    return img

# 提取经二值化后的图片中的手写数字，返回数字图片数组
def get_digit(img):
    # 标记图片中的连通区域，采用8邻域标记，并设置背景像素为0（即黑色）
    # 返回值一个是被标记的数组
    label_image = label(img,connectivity=2,background=0)
    # 获取连通区域的属性列表
    properties = regionprops(label_image)
    # 存放被切割出来的连通区域的列表
    image_list = []

    # 切割连通区域
    for prop in properties:
        # 获得每个连通区域的边界外接框
        min_row,min_col,max_row,max_col = prop.bbox
        # 根据边界外接框提取图像中连通区域
        temp_image = img[min_row:max_row,min_col:max_col]
        
        # 为图像填充边，使其边上留有一定的空白，并且将图像填充为正方形
        height = max_row - min_row
        wide = max_col - min_col
        max_length = max(height,wide)
        final_length = 1.2 * max_length        # 最终的边长为最大边长的1.2倍
        extend_height = int((final_length - height) / 2)
        extend_wide = int((final_length - wide) / 2)
        image = cv2.copyMakeBorder(temp_image,extend_height,extend_height,extend_wide,extend_wide,
                                cv2.BORDER_CONSTANT,value=0)        # 填充边，并且填充的像素为0

        # 设置图像大小为28×28，如果直接指定尺寸的话，必须是元组
        image = cv2.resize(image,(28,28))
        # 将最终的图像加入列表
        image_list.append(image)
    
    # 返回图像数组
    return np.array(image_list)
```

二、卷积神经网络
======
关于卷积神经网络，在之前的博客里面已经说的很清楚了，所以这里就不多做介绍了。
这一次我用了两个卷积层，两个池化层，全连接层中有1024个神经元，并且在全连接层和输出层之间使用了dropout。经过50轮的迭代训练后，在测试集上的准确率为99.24%。

此部分的代码放在了cnn.py模块中。代码如下：
```py
import numpy as np
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import os
from time import time

# 读取mnist数据
mnist = input_data.read_data_sets('MNIST_data/',one_hot=True)

# 参数设置
train_epochs = 50    # 训练轮次
learning_rate = 0.0001    # 学习率
batch_size = 50    # 单次训练样本数（批次大小）
total_batch = int(mnist.train.num_examples / batch_size)    # 一轮训练有多少批次
display_batch = 100    # 批次显示粒度
display_step = 1    # 迭代轮次显示粒度
save_step = 1    # 存储模型的粒度

# 定义权值
def weight(shape):
    return tf.Variable(tf.truncated_normal(shape,stddev=0.1),name='W')

# 定义偏置
def bias(shape):
    return tf.Variable(tf.zeros(shape),name='b')

# 定义卷积操作
# 步长为1,padding为'SAME'
def conv2d(x,W):
    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')

# 定义池化操作
# 步长为2,即原尺寸的长和宽各除以2
def max_pool_2x2(x):
    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')

# 输入层
# 28x28图像，通道为1
with tf.name_scope('input_layer'):
    x = tf.placeholder(tf.float32,shape=[None,28,28,1],name='x')
    
# 第一个卷积层
# 输入通道：1,输出通道：32,卷积后图像尺寸不变，依然是28x28
with tf.name_scope('conv_1'):
    W1 = weight([3,3,1,32])    # [k_height,k_width,input_chn,output_chn]
    b1 = bias([32])    # 与output_chn一致
    conv_1 = conv2d(x,W1) + b1
    conv_1 = tf.nn.relu(conv_1)
    
# 第一个池化层
# 将28x28图像缩小为14x14,池化不改变通道数量，因此依然是32个
with tf.name_scope('pool_1'):
    pool_1 = max_pool_2x2(conv_1)
    
# 第2个卷积层
# 输入通道：32，输出通道：64，卷积后图像尺寸不变，依然是14x14
with tf.name_scope('conv_2'):
    W2 = weight([3,3,32,64])
    b2 = bias([64])
    conv_2 = conv2d(pool_1,W2) + b2
    conv_2 = tf.nn.relu(conv_2)
    
# 第2个池化层
# 将14x14图像缩小为7x7，池化不改变通道数量，因此依然是64个
with tf.name_scope('pool_2'):
    pool_2 = max_pool_2x2(conv_2)
    
# 全连接层
# 将第2个池化层的64个7x7的图像转换为一维的向量，长度是64×7×7=3136
# 1024个神经元
with tf.name_scope('fc'):
    W3 = weight([3136,1024])    # 有1024个神经元
    b3 = bias([1024])
    # -1是指未设定行数，程序随机分配，所以这里的含义为(任意行，3136列)
    flat = tf.reshape(pool_2,[-1,3136])
    h = tf.nn.relu(tf.matmul(flat,W3) + b3)
    # 采用dropout
    h_dropout = tf.nn.dropout(h,keep_prob=0.8)
    
# 输出层
# 输出层共有10个神经元，对应到0-9这10个类别
with tf.name_scope('output_layer'):
    W4 = weight([1024,10])
    b4 = bias([10])
    # 训练时用pred_dropout，测试时用pred
    pred = tf.nn.softmax(tf.matmul(h,W4) + b4)
    pred_dropout = tf.nn.softmax(tf.matmul(h_dropout,W4) + b4)

with tf.name_scope('optimizer'):
    # 定义占位符
    y = tf.placeholder(tf.float32,shape=[None,10],name='labels')
    # 定义使用dropout的损失函数
    loss_function_dropout = tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits(logits=pred_dropout,labels=y))
    # 定义无dropout的损失函数
    loss_function = tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y)) 
    # 选择优化器
    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_function_dropout)

with tf.name_scope('evaluation'):
    # 记录预测正确与否的张量
    # 这里用的是未经dropout的prep
    correct_prediction = tf.equal(tf.argmax(pred,axis=1),tf.argmax(y,axis=1))
    # 正确率
    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))

# 训练轮数（由0开始）
epoch = tf.Variable(0,name='epoch',trainable=False)

# 定义会话及变量初始化
sess = tf.Session()
init = tf.global_variables_initializer()
sess.run(init)

# 设置检查点存储目录
ckpt_dir = 'mnist_ckpt/'
if not os.path.exists(ckpt_dir):
    os.makedirs(ckpt_dir)
    
# 生成saver
# max_to_keep表示要保留的最近文件的最大数量，默认为5
saver = tf.train.Saver(max_to_keep=5)

# 如果有检查点文件，读取最新的检查点文件，恢复各种变量值
ckpt = tf.train.latest_checkpoint(ckpt_dir)
if ckpt != None:
    saver.restore(sess,ckpt)    # 加载所有参数
else:
    print('无训练模型文件，加载失败！')

if __name__ == "__main__":
    # 记录训练开始时间
    start_time = time()

    # 获取续训参数
    start = sess.run(epoch)
    if start < train_epochs:
        print('Training starts from %d epoch.' % (start + 1))

    # 迭代训练
    for ep in range(start,train_epochs):
        for batch in range(total_batch):
            xs,ys = mnist.train.next_batch(batch_size)
            # 将xs转变为4维数组
            xs = xs.reshape([batch_size,28,28,1])
            sess.run(optimizer,feed_dict={x:xs,y:ys})
            if (batch + 1) % display_batch == 0:
                print('Train Batch: %d' % (batch + 1))
            
        # total_batch个批次训练完成后，使用验证数据计算误差与准确率
        # 别忘了将喂给x的数据reshape
        loss,acc = sess.run([loss_function,accuracy],
                        feed_dict={x:mnist.validation.images.reshape([mnist.validation.num_examples,28,28,1]),
                                    y:mnist.validation.labels})
        
        # 更新epoch变量的值    
        sess.run(epoch.assign(ep + 1))
        
        if (ep + 1) % display_step == 0:
            # 打印损失值与准确率
            print('Train Epoch: %02d,  Loss= %.9f,  Accurary= %.4f'
                % (ep + 1,loss,acc))
            
        if (ep + 1) % save_step == 0:
            # 训练过程中存储模型
            saver.save(sess,os.path.join(ckpt_dir,'mnist_model_{:06d}'.format(ep + 1)))
            print('mnist_model_{:06d} saved'.format(ep + 1))
            
    # 显示运行总时间
    duration = time() - start_time
    print('Train Finished takes: %.2f' % (duration))

    # 测试集上的正确率
    acc_test = sess.run(accuracy,
                        feed_dict={x:mnist.test.images.reshape([mnist.test.num_examples,28,28,1]),
                                y:mnist.test.labels})
    print('test accuracy: %.4f' % acc_test)

# 返回当前会话
def get_session():
    return sess

# 对输入的图片数组进行预测，并返回预测值
def predict(session,image_list):
    # 由于pred预测结果是one hot编码格式，所以需要转换为0～9的数字
    prediction_result = session.run(tf.argmax(pred,axis=1),
                                 feed_dict={x:image_list})
    return prediction_result
```

三、最终实现
======
最后的实现放在了main.py模块中。
代码如下：
```py
import cnn
import imgprocess
import matplotlib.pyplot as plt

def plot_prediction(images,    # 图像列表
                    prediction, # 预测值列表   
                    index,      # 从第index个开始显示
                    num=10):    # 一次显示num幅图片
    fig = plt.gcf()    # 获取当前图表，Get Current Figure
    
    # 设置图表大小，两个参数分别为宽和高，单位为英寸，1英寸等于2.54cm
    fig.set_size_inches(10,12)
    
    if num > 25:
        num = 25    # 最多显示25个子图
    for i in range(0,num):
        # 将当前的图表分为5行5列，共计25个子图，并定位到其中的第i+1个子图
        ax = plt.subplot(5,5,i+1)
        
        # 显示第index个图像
        ax.imshow(images[index],cmap='binary')
        
        # 构建该图上要显示的title信息，这里的labels[index]为一维数组，所以不需要指定axis
        title = ''
        if len(prediction) > 0:    # 如果预测值不为空
            title += 'predict=' + str(prediction[index])    # 加入预测值信息
        
        ax.set_title(title,fontsize=10)    # 显示图上的title信息
        ax.set_xticks([])    # 不显示坐标轴
        ax.set_yticks([])
        index += 1
    plt.show()

if __name__ == "__main__":
    # 图片文件路径
    image_path = 'Source/demo.png'
    # 将图片背景像素置为0,并将其二值化
    image = imgprocess.image_init(image_path)
    # 切割出图片中手写数字
    digits = imgprocess.get_digit(image)
    # 归一化处理
    digits = digits / 255
    # 获取当前会话
    sess = cnn.get_session()
    # 获取预测值，别忘了将喂给x的数据reshape成四维的
    prediction = cnn.predict(sess,digits.reshape([-1,28,28,1]))
    # 打印预测值及其对应的手写数字
    plot_prediction(digits,prediction,0,len(digits))
    # 关闭会话
    sess.close()
```