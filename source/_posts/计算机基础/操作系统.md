---
title: 操作系统
date: 2023-07-16 10:41:37
mathjax: true
categories: 计算机基础
tags: 
- 操作系统
---
# 1 冯诺依曼模型

<!--more-->

冯诺依曼定义计算机基本结构为5个部分：控制器、运算器、存储器、输入设备、输出设备。

![](操作系统/fig1.jpg)

当然，其中还存在总线用于各部分的之间的通信，总线可以分为以下几种：

- 控制总线：发送和接收信号，比如中断、设备复位等信号。
- 数据总线：用于读写内存的数据。
- 地址总线：用于指定CPU将要操作的内存地址。

另外，CPU中还存在着多种寄存器，寄存器主要可以分为以下几种：

- 通用寄存器：用来存放需要进行运算的数据。
- 程序计数器：用来存储CPU要执行下一条指令的内存地址。
- 指令寄存器：用来存放程序计数器指向的指令，也就是指令本身。

# 2 CPU Cache

为了缓解内存与CPU之间读写速度的不一致，计算机中会设置高速缓存，通常可以分为L1、L2、L3三级高速缓存，L1和L2缓存是每个CPU核心独有的，而L3缓存是多个CPU核心共享的。

![](操作系统/fig3.png)

## 2.1 Cache Line

Cache中由多个Cache Line组成，每个Cache Line的大小为64字节（Cache Line中所能存储的数据的大小）。

内存映射到Cache中的方式主要有以下三种：

- 直接映射：一个Cache Line就是一个组。
- 组相联：多个Cache Line组成一个组，当使用Index找到对应的组之后，需要遍历组来找到对应的Cache Line。
- 全相联：所有的Cache Line看作一个组。这种情况下不再需要Index，需要遍历整个Cache来找到对应的Cache Line（并行匹配tag，而不是顺序遍历查找，需要硬件电路支持）。

下面是直接映射的一个示例：

![](操作系统/fig2.png)

##  2.2 CPU Cache的数据写入

当我们修改了Cache中的数据之后，内存与Cache中的数据就会发生不一致，所以我们要在合适的时间将Cache中的脏数据写入到内存中。

主要有以下两种写入方式：

- **写直达（Write Through）**：将修改写入到Cache中的同时，将对应的修改写入到内存中。
- **写回（Write Back）**：仅将修改写入到Cache中，只有到修改过的Cache Line被替换时，才将修改写入到内存。

## 2.3 MESI协议解决缓存一致性问题

前面我们提到过，L1/L2 Cache是多个核心各自独有的，因此会带来**多核心的缓存一致性问题**。注意，这里说的是多个核心中缓存之间的一致性，而不是缓存与内存之间的一致性。

MESI协议就是用于解决多核心的缓存一致性问题的，MESI其实是4个状态单词的开头缩写，用来标记Cache Line四个不同的状态：

- **Modified（已修改）**：也就是脏标记，表示该Cache Line上的数据已经被修改过，但是还没有写入到内存中。
- **Exclusive（独占）**：独占状态下，数据只存储在一个CPU核心的Cache中，其他CPU核心的Cache中没有该数据。这种情况下，可以直接修改该Cache Line中的数，而不需要通知其他CPU核心。
- **Shared（共享）**：共享状态表示相同的数据在多个CPU核心的Cache中都有，所以当我们要修改该Cache Line中的数据时，不能直接修改，需要先向所有的其他CPU核心广播一个请求，要求把其他核心的Cache中对应的Cache Line标记为Invalidated（已失效），然后再修改当前Cache中的数据。
- **Invalidated（已失效）**：表示该Cache Line中的数据已经失效了，不可以读取该状态的数据。

# 3 内存管理

## 3.1 虚拟内存

如果进程可以直接访问物理内存，有可能破坏其他进程甚至操作系统的内存数据，造成其他进程甚至是操作系统崩溃。

因此，现代的操作系统引入了**虚拟内存**。进程访问的内存地址不再是实际的物理地址，而是一个虚拟地址，然后由操作系统将虚拟地址映射到适当的物理内存中。每个进程的虚拟内存空间都是独立的，互不干扰。

MMU（Memory Management Unit，存储器管理单元）负责完成由虚拟地址到物理地址的翻译。

虚拟内存的管理方式主要有以下几种：

- 段式
- 页式
- 段页结合式

## 3.2 段式内存管理

段式管理下的虚拟内存地址由两部分组成：段号和段内地址（段内偏移）。

![](操作系统/fig4.png)

进行虚拟地址到物理地址的映射时，先通过段号查询段表，得到段的基址，然后再加上段内偏移，就可以找到该虚拟地址对应的物理地址。

![](操作系统/fig5.png)

段式内存管理会导致**内存碎片**的问题。

## 3.3 页式内存管理

### 3.3.1 介绍

页式内存管理将虚拟内存和物理内存都划分为许多大小相等的**页（Page）**，一个页的大小通常为4KB。类似于段式管理，页式管理下的虚拟内存也被分为两部分：页号和页内偏移。

内存地址转换的大致步骤如下：

- 将虚拟内存地址切分为页号和偏移量。
- 根据页号，从页表中查询到对应的物理页号。
- 物理页号加上页内偏移就组成了物理内存地址。

![](操作系统/fig6.png)

需要注意的是，页表项中是没有虚拟页号的，虚拟页号只是作为查询页表时页表项的索引。

### 3.3.2 多级页表

为了解决页表占用空间过大的问题，引入了**多级列表**。也就是说一级页表中存放的不再是物理

![](操作系统/fig7.png)

比如上面的二级页表，一级页表中存储的不再是物理页号，而是二级页表的起始地址。找到二级页表之后，再根据二级页号作为索引找到对应的物理页号。

如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表，只有在用到时才创建二级页表，大大节省了空间。

### 3.3.2 TLB快表

为了加快虚拟地址转换为物理地址的速度，MMU中设置了一个存储页表项的Cache，称为TLB（Translation Lookaside Buffer），中文通常称为快表。

有了快表之后，原来的虚拟地址中的页号又可以细分为TLB tag和TLB index，地址的切分与之前所说的查找Cache的地址切分一致（其实TLB本身就是Cache）。

![](操作系统/fig8.png)

有了TLB之后，那么在进行地址转换时会先查TLB，如果没查到，再去查常规的页表。通常，由于局部性原理，通常TLB的命中率还是挺高的。

## 3.4 段页式内存管理

段页式内存管理中将内存分为不同的段，每个段又可以分为多个页。在这种情况下，虚拟地址就由段号、段内页号和页内偏移三部分组成。

![](操作系统/fig9.png)

# 4 局部性原理

局部性主要有：

- **时间局部性**：同一个内存位置，从时间维度来看，它在较短时间内很可能被多次引用（循环）。
- **空间局部性**：同一个内存位置，从空间维度来看，它附近的内存位置也很有可能被引用。

# 5 进程间通信

每个进程的用户地址空间都是独立的，一般而言是不能相互访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。

Linux提供了以下几种进程间通信的机制：

- **管道**
  - 管道主要可以分为匿名管道和有名管道：
    - **匿名管道**：匿名管道的通信范围是存在亲缘关系（父子进程或兄弟进程）的进程。
      因为匿名管道没有名字，所以只能通过`fork`来复制父进程`fd`文件描述符，来达到通信的目的。
    - **有名管道**：有名管道在不存在亲缘关系的进程间也能相互通信。
      - 有名管道不同于匿名管道之处在于它提供了一个路径名与之关联，以有名管道的文件形式存放在文件系统中。
      - 即使是与有名管道的创建进程不存在亲缘关系的进程，只要可以访问该路径，就可以通过有名管道进行通信。
  - 管道是半双工的，数据只能向一个方向流动，并且传输的是**无格式的字节流**。
  - 当创建管道的进程结束之后，管道也会被销毁。
- **消息队列**：消息队列是保存在内核中的消息链表，一个消息队列由一个标识符（即队列ID）来标识。
  - 消息队列是**面向记录**的，其中的消息有特定的格式以及特定的优先级（消息体是用户自定义的数据类型）。
  - 消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取，也可以按消息的类型读取。
  - 由于消息队列保存在内核中，因此即使进程终止，消息队列也不会销毁。
  - 消息队列通信过程中，存在用户态到内核态之间的数据拷贝开销。
- **共享内存**：共享内存就是拿出一块虚拟地址空间，映射到相同的物理内存中。
  - 共享内存是最快的一种进程通信方式，因为进程直接读写内存，而且不需要进行数据的拷贝。
  - 由于多个进程共享一段内存，因此通常需要结合信号量来实现进程间的同步及互斥。
- **信号量**：信号量用于实现进程间的互斥与同步，而不是存储进程间通信数据。
- **信号**：
  - 信号是进程间通信机制中唯一的**异步通信机制**。
  - 信号可以在任何时候发给某一进程，而无需知道该进程的状态。
- **Socket**：Socket通信可以通过网络连接实现不同主机之间的进程通信，当然，也可以实现同主机上的进程通信。

**参考资料**：

[进程间通信IPC (InterProcess Communication)](https://www.jianshu.com/p/c1015f5ffa74)

[进程间的五种通信方式介绍-详解](https://learnku.com/articles/44477)

# 6 线程同步的方法

- 信号量
- 条件变量：需要配合锁使用。

# 7 死锁

死锁是指多个线程或进程在运行过程中因争夺资源而造成的一种僵局，当线程或进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进。

## 7.1 产生死锁的必要条件

死锁的产生需要满足以下几个必要条件：

- **互斥条件**：多个线程不能同时占用同一个资源。如果有其他线程请求已被占用的资源，则请求者只能阻塞等待，直到占用该资源的线程释放资源。
- **请求与保持条件**：线程在因请求资源被阻塞等待时，不会释放自己持有的资源。
- **不可剥夺条件**：进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。
- **环路等待条件**：多个线程之间形成一种资源等待的环形链。比如线程1等待线程2占用的资源，线程2等待线程3占用的资源，线程3又等待线程1占用的资源。

## 7.2 处理死锁的基本方法

为保证系统中诸进程的正常运行，应事先采取必要的措施，来预防发生死锁。在系统中已经出现死锁后，则应及时检测到死锁的发生，并采取释放的措施来解决死锁。目前，处理死锁的方法可归结为以下四种：

- **预防死锁**。这是一种较简单和直观的实现预防的方法。该方法是通过设置某些限制条件，去破坏产生死锁的四个必要条件中的一个或几个条件，来预防发生死锁。
- **检测死锁**。这种方法允许系统在运行过程中发生死锁，但可以及时的检测出死锁的发生，然后采取适当措施，将系统中的死锁清除掉。
- **解除死锁**。与检测死锁相配套，当检测到系统中已发生死锁时，需要将进程从死锁状态中解脱出来。

## 7.3 预防死锁

预防死锁的条件是使四个必要条件中的第2、3、4个条件之一不能成立，来避免发生死锁。至于必要条件1，我们不仅不能改变，还应加以保证。

- **摒弃请求与保持条件**。所有进程在开始运行之前，都必须一次性的申请其在整个运行过程中所需的全部资源。只要有一种资源不能满足某进程的要求，即使其他所需的各资源都空闲，也不分配给该进程，而让该进程等待。
- **摒弃不可剥夺条件**。当一个保持了某些资源的进程，再提出新的资源请求而不能立即得到满足时，必须释放它已经保持了的所有资源，待以后需要时再重新申请。
- **摒弃环路等待条件**。这种方法规定，系统对所有资源进行顺序编号，所有进程对资源的请求必须严格按照资源序号递增的次序提出。这样，在所形成的资源分配图中，不可能再出现环路，因此摒弃了环路等待条件。

## 7.4 检测死锁

系统死锁可利用**资源分配图**来描述。

![](操作系统/fig18.png)

由资源指向进程的是资源分配边，表示将一个单位的资源分配给进程。由进程指向资源的是资源请求边，它表示进程请求一个单位的资源。

例如，图中$p_{1}$进程已经分得了两个$r_{1}$资源，并又请求一个$r_{2}$资源；$p_2$进程已经分得了一个$r_{1}$和$r_{2}$资源，并又请求$r_{1}$资源。

我们可以利用把资源分配图加以简化的方法，来检测系统是否为死锁状态。简化方法如下：

1. 在资源分配图中，找出一个即不阻塞又非独立的进程结点$P_{1}$。在顺利的情况下，$P_{1}$可获得所需资源而继续运行，直至运行完毕，再释放其所占有的全部资源，这相当于消去$P_{1}$的请求边和分配边，使之成为孤立的结点。
2. $P_{1}$释放资源后，便可使$P_{2}$获得资源而继续运行，直至完成$P_{2}$完成后又释放出它所占有的全部资源。
3. 在经过一系列的简化后，若能消去图中所有的边，使所有的进程结点都成为孤立结点，则称该图是可完全简化的；若不能通过任何过程使该图完全简化，则称该图是不可完全简化的。

![](操作系统/fig19.png)

系统处于死锁状态的**充分条件**是：当且仅当系统当前状态的资源分配图是不可完全简化的。

Java可以用`jstack`工具检测死锁，只需要输入`jstack java进程号`即可。

## 7.5 解除死锁

在检测到发生死锁之后，应当立即解除死锁。常采用的解除死锁的两种方法是：

- 剥夺资源。从其他进程剥夺足够数量的资源给死锁进程，以解除死锁状态。
- 撤销进程。逐个撤销死锁进程，直至有足够的资源可用，使死锁状态消除为止。

## 7.6 进程死锁的危害

- 死锁会使**进程无法正常执行**。因为处于死锁状态的进程得不到所需的资源，不能向前推进，故得不到结果。
- 死锁会使**资源的利用率降低**。因为处于死锁状态的进程不释放已占有的资源，以至于这些资源不能被其他进程利用，故系统资源利用率降低。
- 死锁还会**导致产生新的死锁**。其他进程因请求不到死锁进程已占用的资源而无法先前推进，所以也会发生死锁。

# 8 进程调度算法

常见的进程调度算法有以下几种：

- **先来先服务（First Come First Severd，FCFS）**：每次从就绪队列选择最早进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。

- **最短作业优先（Shortest Job First，SJF）**

  - 优先选择运行时间最短的进程来运行。
  - 可能导致长作业永远不会被执行。

- **高响应比优先（Highest Response Ratio Next，HRRN）**

  ```
  响应比 = (等待时间+要求服务时间) / 要求服务时间
  ```

  - 每次进行进程调度时，首先计算响应比，然后将响应比最高的进程投入运行。
  - 高响应比优先算法权衡了短作业和长作业，即可以使短作业优先执行，也不会使长作业等待太长的时间。

- **时间片轮转**：每个进程被分配一个时间片，如果时间片用完，则切换其他进程运行。
- **最高优先级**：每次调度从就绪队列中选择优先级最高的进程运行。
  
  - 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再调度优先级高的进程运行。
  - 抢占式：当就绪队列中出现优先级高的进程，将当前进程挂起，调度优先级高的进程运行。
  - 可能会导致低优先级的进程永远不会运行。
- **多级反馈队列**：
  ![](操作系统/fig10.png)
  - 设置多个队列，每个队列具有不同的优先级，每个队列**优先级从高到低**，同时**优先级越高时间片越短**。
  - 新的进程会被放到第一级队列的末尾，按先来先服务的原则排队等待调度，如果进程没有在第一级队列规定的时间片内运行完成，则将其转入到第二级队列的末尾，以此类推，直至进程执行完成。
  - 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到远队列末尾，接着让高优先级的进程运行（抢占式）。

# 9 内存页面置换算法

当CPU访问的页面不在物理内存时，会产生一个**缺页中断**，请求操作系统将所缺的页调入到物理内存。如果物理内存已满，则需要选择一个物理内存中的页面换出到磁盘，然后把需要访问的页面换入到物理内存中。而选择哪个物理内存中的页面进行换出，就需要页面置换算法了。

常见的页面置换算法有以下几种：

- **最佳页面置换算法**：置换在未来最长时间不访问的页面。但由于人们目前无法阈值一个进程在内存的若干个页面中，哪一个页面是未来最长时间内不再被访问的，因此该算法是无法实现的。但是我们可以利用该算法去评价其他算法。
- **先进先出置换（FIFO）算法**：淘汰最先进入内存的页面，也就是在内存中驻留时间最久的页面。
- **最近最久未使用（Least Recently Used，LRU）置换算法**：选择最近最久未使用的页面予以淘汰。
- **Clock置换算法**：为每页设置一个访问位，再将内存中的所有页面都通过指针链接成一个循环链表。
  - 当某页被访问时，其访问位被置为1。
  - 置换算法在选择一页淘汰时，只需检查页的访问位。
    - 如果是0，就选择该页换出。
    - 若为1，则重新将它置为0，暂不换出，而给该页第二次驻留内存的机会，再按照FIFO算法检查下一个页面。
- **最少使用（Least Frequently Used，LFU）置换算法**：选择访问次数最少的页面，并将其淘汰。

# 10 磁盘调度算法

磁盘设备在工作时以恒定速率旋转，磁盘在读写数据时，需要先将磁头移动到对应的磁道上，并等待对应的扇区的开始位置旋转到磁头下，然后再开始读写数据。因此，磁盘的访问时间主要分为三部分：寻道时间、旋转时间、传输时间。其中，寻道时间最长。

磁盘调度算法的目标就是使磁盘的**平均寻道时间最少**，主要有以下几种算法：

- **先来先服务（FCFS，First Come First Served）**：先来到的请求，先被服务。
  ![](操作系统/fig11.png)

- **最短寻道时间优先（SSTF，Shortest Seek Time First）**：
  ![](操作系统/fig12.png)
  - 优先选择要求访问的磁道与当前磁头所在磁道距离最近的请求，以使每次请求的寻道时间最短，但是不能保证平均寻道时间最短（贪心）。
  - 可能产生饥饿现象（磁头在一小块区域来回移动）。
- **扫描（SCAN）算法**：磁头在一个方向上移动时，处理完该方向上的所有请求之后，才调换方向。比如刚开始从里向外移动，处理该方向上的请求，直到再无更外的磁道需要访问时，再从外向里移动。
  ![](操作系统/fig13.png)

- **循环扫描（CSCAN）算法**：SCAN算法规定磁头单向移动。例如只是自里向外移动，当磁头移动到最外需要访问的磁道后，磁头立即返回到最里的欲访问的磁道。
  ![](操作系统/fig14.png)

# 11 零拷贝

**零拷贝（Zero-Copy）**是一种I/O操作优化技术，使用零拷贝的I/O不再需要将数据从内核空间拷贝到用户空间，提高了I/O的效率。

## 11.1 传统I/O存在的性能问题

如果服务端要提供文件传输的功能，最简单的方式就是：将磁盘上的文件读取出来，然后通过网络协议发送给客户端。一般会用到下面两个系统调用：

- `read(file, tmp_buf, len)`：将数据从磁盘读取到内核缓冲区，再拷贝到用户缓冲区。
- `write(socket, tmp_buf, len)`：先把数据写入到socket缓冲区，最后写入网卡设备。

具体流程如下：

![](操作系统/fig17.awebp)

期间，发生了**4次上下文切换**，因为发生了两次系统调用`read`和`write`，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。

另外，还**发生了4次数据拷贝**，其中两次是DMA的拷贝，另外两次则是通过CPU拷贝的，具体过程如下：

- 第一次拷贝：把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝过程是由DMA完成的。
- 第二次拷贝：把内核缓冲区的数据拷贝到用户缓冲区中，这个拷贝过程是由CPU完成的。
- 第三次拷贝：把刚才拷贝到用户缓冲区中的数据，再拷贝到内核的socket缓冲区中，这个拷贝过程是由CPU完成的。
- 第四次拷贝：将内核的socket缓冲区中的数据，拷贝到网卡的缓冲区中，这个拷贝过程是由DMA完成的。

上下文切换和内存拷贝都是比较消耗资源的，所以我们要想提高文件传输的性能，就需要**减少上下文切换和内存拷贝的次数**。

## 11.2 零拷贝实现

### 11.2.1 mmap+write方式

现代操作系统都使用虚拟内存，使用虚拟地址取代物理地址，并且**不同的虚拟地址可以映射到同一个物理地址**。

我们可以利用了虚拟内存的这一特点，将**内核缓冲区和用户缓冲区的虚拟地址映射到同一个物理地址**，这样的话，就可以减少IO的数据拷贝次数了。

![](操作系统/fig18.awebp)

我们可以利用`mmap`替换`read`系统调用，`mmap`系统调用可以将内核空间和用户空间的虚拟地址映射到同一个物理地址，从而减少数据拷贝次数。

![](操作系统/fig19.jpg)

可以发现，`mmap`加上`write`实现的零拷贝，发生了**4次上下文切换**和**3次数据拷贝**。其中3次数据拷贝中，包括了2次DMA拷贝和1次CPU拷贝。

另外，由于内核缓冲区与应用缓冲区映射到了同一块物理内存，共享一块物理内存，因此可以节省一半的内存空间。

### 11.2.2 sendfile方式

`sendfile`表示在两个文件描述符之间传输数据，它是在操作系统内核中操作的，避免了数据从内核缓冲区和用户缓冲区之间的拷贝操作，因此可以用`sendfile`实现零拷贝。

`sendfile`实现的零拷贝流程如下：

![](操作系统/fig20.jpg)

可以发现，`sendfile`实现的零拷贝中，发生了**2次上下文切换**（只使用了`sendfile`这一个系统调用）和**3次数据拷贝**。其中3次数据拷贝中，包括了2次DMA拷贝和1次CPU拷贝。

### 11.2.3 sendfile+DMA scatter/gather方式

linux2.4版本后，对`sendfile`做了优化升级，引入SG-DMA技术，其实就是对DMA拷贝加入了`scatter/gather`操作，它可以直接从内核缓冲区中将数据读取到网卡（需要硬件支持）。

其原理就是CPU将内核缓冲区中的**文件描述符信息**（包括内核缓冲区的内存地址和偏移量）饭送到socket缓冲区，然后DMA控制器就可以根据文件描述符信息，直接把数据从内核缓冲区拷贝到网卡。

![](操作系统/fig21.jpg)

可以发现，`sendfile`加`DMA scatter/gether`实现的零拷贝，发生了**2次上下文切换**，以及**2次数据拷贝**，其中2次数据拷贝都是DMA拷贝。

这就是真正的零拷贝技术，全程都没有通过CPU来搬运数据，所有的数据都是通过DMA进行传输的。

## 11.3 补充：DMA

**DMA（Direct Memory Access）**，即直接内存访问。DMA本质上是一块主板上独立的芯片，允许外部设备和内存之间直接进行IO数据传输（不能控制内存之间的数据传输），而不需要CPU的干预。

![](操作系统/fig22.jpg)

- 用户应用进程调用`read`方法，向操作系统发起IO请求，请求读取数据到自己的内存缓冲区中，进入阻塞状态，等待数据返回。
- CPU收到指令后，将请求发送给DMA，此时CPU就可以去做其他事情了。
- DMA收到IO请求后，将请求发送给磁盘。
- 磁盘将数据放入磁盘控制器缓冲区，并通知DMA。
- DMA收到磁盘的信号后，将数据从磁盘控制器缓冲区拷贝到内核缓冲区。
- DMA向CPU发出数据读完的信号，由CPU将数据从内核缓冲区拷贝到用户缓冲区。
- 用户应用进程由内核态切换回用户态，解除阻塞状态。

可以看到，整个数据传输的过程，都是由DMA完成的，CPU只需要发送请求给DMA，就可以去做其他事情了。当DMA完成数据传输后，会向CPU发送中断信号，此时CPU再来进行后续处理。

**参考资料**：

[看一遍就理解：零拷贝详解](https://heapdump.cn/article/3290793)

[一文彻底弄懂零拷贝原理](https://juejin.cn/post/6995519558475841550)

# 12 进程与线程

由**程序段**、**相关的数据段**和**PCB**三部分便构成了进程实体。

## 12.1 PCB

在操作系统中，使用进程控制块PCB（Process Control Block）这一数据结构来描述进程。**PCB是进程存在的唯一标识**，一般说的创建进程，实际上是创建进程实体中的PCB；而撤销进程，实际上是撤销进程的PCB。

PCB中主要包含以下信息：

- **进程标识符**。进程标识符用于惟一的标识一个进程。
- **CPU状态信息**。当进程发生上下文切换时，需要将当前的CPU状态信息存储到该进程的PCB中，以便进程重新执行时，能从断点处继续执行。主要包括如下几部分：
  - **通用寄存器**。它们是用户程序可以访问的，用于暂存信息。
  - **指令计数器**。其中存放了要访问的下一条指令的地址。
  - **程序状态字PSW**。其中含有状态信息，如条件码、执行方式、中断屏蔽标志等。
  - **用户栈指针**。每个用户进程都有一个或若干个与之相关的系统栈，用于存放过程和系统调用参数及调用地址，栈指针指向该栈的栈顶。
- **进程调度信息**
  - **进程状态**。指明进程的当前状态，作为进程调度时的依据（新建、就绪、运行、阻塞、终止）。
  - **进程优先级**。优先级高的进程应当优先获得CPU。
  - **进程调度所需的其他信息**。比如进程已等待CPU的时间总和、进程已执行的时间总和等。
  - **事件**。指进程由执行状态转变为阻塞状态所等待发生的时间，即阻塞原因。
- **进程控制信息**
  - **程序和数据的地址**。指进程的程序和数据所在的内存或外存地址，以便再调度到该进程执行时，能从PCB中找到其程序和数据。
  - **进程同步和通信机制**。指实现进程同步和进程通信时必须的机制，如消息队列指针、信号量等。
  - **资源清单**：即一张列出了除CPU以外的，进程所需的全部资源及以分配到该进程的资源的清单（如拥有的IO设备和打开的文件列表）。
  - **链接指针**。根据进程的状态不同，进程的PCB会被加入到不同的队列中。该链接指针指向该进程所在队列中下一个进程PCB的首地址。

## 12.2 PCB的组织方式

操作系统通常使用链表的方式对PCB进行组织，将**具有相同状态的进程的PCB链接到一起**，组成各种队列。比如：

- 将所有处于就绪状态的进程链接在一起，称为**就绪队列**。
- 将所有因等待某时间而处于阻塞状态的进程链接在一起就组成了**阻塞队列**。

![](操作系统/fig17.png)

## 12.3 进程的创建

进程的创建大致可分为以下几步：

- 为新进程分配一个唯一的进程标识符，并申请一个空白的PCB。
- 为新进程分配资源。也就是为新进程的程序和数据以及用户栈分配必要的内存空间。
- 初始化PCB。
  - 初始化标识信息。将系统分配的标识符和父进程标识符填入新PCB中。
  - 初始化CPU状态信息。令程序计数器指向程序的入口地址，令栈指针指向栈顶。
  - 初始化CPU控制信息。将进程的状态设置为就绪态，对于优先级，通常是将它设置为最低优先级，除非用户以显式方式提出高优先级要求。
- 将新进程插入就绪队列。

## 12.4 线程

同一个进程内多个线程之间可以**共享代码段、数据段、打开的文件等资源**，但**每个线程各自都有一套独立的寄存器和栈**，这样可以确保线程的控制流是相对独立的。

**参考资料**：

[Linux下的进程控制块(PCB)](https://www.cnblogs.com/yungyu16/p/13024626.html)